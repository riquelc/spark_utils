Metadata-Version: 2.4
Name: spark-utils
Version: 0.1.0
Summary: Biblioteca de utilitários para manipulação de dados no Apache Spark
Home-page: https://github.com/seu-usuario/spark-utils
Author: Henrique Lamera Carvalho
Author-email: henrique.lamera@icloud.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pyspark>=3.0.0
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

<<<<<<< HEAD
# spark_utils
=======
# Spark Utils - Biblioteca de Utilitários para Spark

Esta biblioteca oferece utilitários para manipulação de dados no Apache Spark, com foco especial em operações com JSON aninhado.

## Funcionalidades Principais

### Aplanamento de JSON
A biblioteca oferece duas opções principais para aplanar estruturas JSON aninhadas:

1. **Modo Reduzido** (`modo='reduzido'`)
   - Mantém apenas os dois últimos níveis da hierarquia
   - Útil quando há campos com o mesmo nome em diferentes estruturas
   - Exemplo: `travelerPricings_fareDetailsBySegment_amenities_isChargeable` → `amenities_isChargeable`

2. **Modo Completo** (`modo='completo'`)
   - Mantém toda a hierarquia completa
   - Útil quando é necessário preservar toda a estrutura original
   - Exemplo: `travelerPricings_fareDetailsBySegment_amenities_isChargeable` → `travelerPricings_fareDetailsBySegment_amenities_isChargeable`

## Como Usar

### Importando a Biblioteca
```python
from spark_utils.flatten import aplanar_json
```

### Exemplo de Uso - Modo Reduzido
```python
# Aplanando com modo reduzido (padrão)
df_aplanado = aplanar_json(df)
```

### Exemplo de Uso - Modo Completo
```python
# Aplanando com modo completo
df_aplanado = aplanar_json(df, modo='completo')
```

## Funções Disponíveis

### `aplanar_json(df: DataFrame, modo='reduzido') -> DataFrame`
Aplana estruturas JSON aninhadas no DataFrame.
- `modo`: 'reduzido' ou 'completo'

### `extrair_nome_niveis(caminho_completo: str) -> str`
Extrai os dois últimos níveis da estrutura.
- Útil para criar nomes únicos em campos com mesmo nome

### `extrair_nome_completo(caminho_completo: str) -> str`
Mantém o nome completo da hierarquia.
- Útil para preservar toda a estrutura original

### `obter_campos_complexos(df: DataFrame) -> dict`
Recupera todos os campos complexos (StructType ou ArrayType) do DataFrame.

## Requisitos
- Python 3.x
- PySpark
- logging

## Instalação

### Instalação via pip
```bash
pip install spark-utils
```

### Instalação local (desenvolvimento)
```bash
# Clone o repositório
# Navegue até o diretório do projeto
python setup.py install
```

### Instalação em ambiente virtual
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
pip install spark-utils
```

### Uso em Databricks
1. Instale o pacote via pip
2. Importe as funções necessárias usando o comando `from spark_utils.flatten import ...`

## Contribuição
Sinta-se à vontade para contribuir com melhorias e novas funcionalidades.

## Licença
MIT
>>>>>>> 4203cc6 (Initial commit: Spark Utils library with JSON flattening utilities)
